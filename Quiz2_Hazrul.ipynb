{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quiz2-Hazrul.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hazrulnizam/MANB2153/blob/master/Quiz2_Hazrul.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "aSXGGVRykMVw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Quiz 2 MANB 2153\n",
        "1\n",
        "\n",
        "Name: Hazrul Nizam bin Sidek\n",
        "\n",
        "Matric Number: MAN181010\n",
        " \n",
        "\n",
        "Questions/Instructions.\n",
        "Answer all questions in a Jupyter Notebook (colab). Push your notebook to your github\n",
        "under Quiz2-Yourfirstname.\n",
        "1. Using the problem and data at https://www.kaggle.com/ronitf/heart-disease-uci,\n",
        "download the data (3KB)\n",
        "\n",
        "2. What type of problem are we trying to solve here? Classification or regression?\n",
        "\n",
        "3. You have decided you want to create a neural network model to perform the\n",
        "classification/regression for that problem.\n",
        "a. Use train_test_split function to split the data into training 70%, test 30%\n",
        "b. Design a neural network model with any architecture. Try to be unique\n",
        "here.\n",
        "c. Use Keras codes to create the model\n",
        "d. Compile and fit the model\n",
        "e. What is the accuracy after 20 epochs?\n",
        "\n",
        "4. What is underfitting and overfitting?\n",
        "\n",
        "\n",
        "5. Explain how you can reduce the overfitting of the model."
      ]
    },
    {
      "metadata": {
        "id": "5QQI20gVlKRY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. The data has been downloaded and saved as 'heart.csv'"
      ]
    },
    {
      "metadata": {
        "id": "JkOtl5lGlTd8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2. From this dataset, we are trying to find out whether a patient has a heart disease or not from other variables. This is a classification problem."
      ]
    },
    {
      "metadata": {
        "id": "GX4mY3F-ls3J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "outputId": "1f05eb63-aa78-41cb-baaa-5464cad8a69a"
      },
      "cell_type": "code",
      "source": [
        "# Answer to question 3\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import adam\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Prepare Data\n",
        "# a. Use train_test_split function to split the data into training 70%, test 30%\n",
        "df = pd.read_csv('heart.csv')\n",
        "y = to_categorical(df['target'])\n",
        "X = df.drop(['target'], axis = 1).as_matrix()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=59)\n",
        "\n",
        "# b. Design a neural network model with any architecture. Try to be unique here.\n",
        "# c. Use Keras codes to create the model\n",
        "model = Sequential()\n",
        "model.add(Dense(1000, activation='relu', input_shape=(X.shape[1],)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1000, activation='selu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1000, activation='selu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# d. Compile and fit the model\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=20)\n",
        "\n",
        "# e. What is the accuracy after 20 epochs?\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print(model.metrics_names[0] + '=' + str(score[0]))\n",
        "print(model.metrics_names[1] + '=' + str(score[1]))\n",
        "#model.metrics_names[0]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 6.4853 - acc: 0.5802\n",
            "Epoch 2/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 3/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 4/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 5/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 6/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 7/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 8/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 9/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 10/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 11/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 12/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 13/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 14/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 15/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 16/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 17/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 18/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 19/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "Epoch 20/20\n",
            "212/212 [==============================] - 0s 2ms/step - loss: 6.9946 - acc: 0.5660\n",
            "91/91 [==============================] - 1s 12ms/step\n",
            "loss=8.147608709859323\n",
            "acc=0.494505491230514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m0_mLrTIwmoM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "4. Underfitting is when the model is not being fed enough data to make reasonable prediction to both training and test data sets. Overfitting is when the model is fitted too much to the training data and gives high accuracy when used on the training data but fails when used on test data that the model has never seen before."
      ]
    },
    {
      "metadata": {
        "id": "FHNW3YDRw_oB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "5. To reduce overfitting, the capacity of the neural network model can be reduced by removing layers or number of nodes."
      ]
    }
  ]
}